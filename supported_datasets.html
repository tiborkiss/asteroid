

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Datasets and tasks &mdash; asteroid 0.0.1 documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://github.com/mpariente/asteroidsupported_datasets.html"/>
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Training and Evaluation" href="training_and_evaluation.html" />
    <link rel="prev" title="What is a recipe?" href="readmes/egs_README.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> asteroid
          

          
            
            <img src="_static/favicon.ico" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.0.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Start here</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="why_use_asteroid.html">What is Asteroid?</a><ul>
<li class="toctree-l2"><a class="reference internal" href="why_use_asteroid.html#who-is-it-for">Who is it for?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="installation.html#cuda-and-pytorch">CUDA and PyTorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#pip">Pip</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#development-installation">Development installation</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Asteroid</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="readmes/egs_README.html">What is a recipe?</a><ul>
<li class="toctree-l2"><a class="reference internal" href="readmes/egs_README.html#how-is-it-organized">How is it organized?</a></li>
<li class="toctree-l2"><a class="reference internal" href="readmes/egs_README.html#how-does-it-work">How does it work?</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Datasets and tasks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#speech-separation">Speech separation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#wsj0-2mix-dataset">wsj0-2mix dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="#wham-dataset">WHAM dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="#whamr-dataset">WHAMR dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="#librimix-dataset">LibriMix dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="#kinect-wsj-dataset">Kinect-WSJ dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="#sms-wsj-dataset">SMS_WSJ dataset</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#speech-enhancement">Speech enhancement</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#dns-challenge-s-dataset">DNS Challengeâ€™s dataset</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#music-source-separation">Music source separation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#musdb18-dataset">MUSDB18 Dataset</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#environmental-sound-separation">Environmental sound separation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#fuss-dataset">FUSS dataset</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#audio-visual-source-separation">Audio-visual source separation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#avspeech-dataset">AVSpeech dataset</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#speaker-extraction">Speaker extraction</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="training_and_evaluation.html">Training and Evaluation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="training_and_evaluation.html#training-with-pytorchlightning">Training with PyTorchLightning</a></li>
<li class="toctree-l2"><a class="reference internal" href="training_and_evaluation.html#evaluation">Evaluation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="readmes/pretrained_models.html">Pretrained models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="readmes/pretrained_models.html#using-them">Using them</a></li>
<li class="toctree-l2"><a class="reference internal" href="readmes/pretrained_models.html#model-caching">Model caching</a></li>
<li class="toctree-l2"><a class="reference internal" href="readmes/pretrained_models.html#share-your-models">Share your models</a></li>
<li class="toctree-l2"><a class="reference internal" href="readmes/pretrained_models.html#note-about-licenses">Note about licenses</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a><ul>
<li class="toctree-l2"><a class="reference internal" href="faq.html#my-results-are-worse-than-the-ones-reported-in-the-readme-why">My results are worse than the ones reported in the README, why?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#how-long-does-it-take-to-train-a-model">How long does it take to train a model?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#can-i-use-the-pretrained-models-for-commercial-purposes">Can I use the pretrained models for commercial purposes?</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Notebooks and Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="http://colab.research.google.com/github/mpariente/asteroid/blob/master/notebooks/01_AsteroidGettingStarted.ipynb">NB: Getting stated with Asteroid</a></li>
<li class="toctree-l1"><a class="reference external" href="http://colab.research.google.com/github/mpariente/asteroid/blob/master/notebooks/02_Filterbank.ipynb">NB: Understanding the Filterbank API</a></li>
<li class="toctree-l1"><a class="reference external" href="http://colab.research.google.com/github/mpariente/asteroid/blob/master/notebooks/03_PITLossWrapper.ipynb">NB: Our PITLossWrapper explained</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/drive/1BDNQZBJCDcwQhSguf3XBE7ff2KXhWu_j">Community NB: Numpy vs. Asteroid STFT</a></li>
</ul>
<p class="caption"><span class="caption-text">Package reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="package_reference/data.html">PyTorch Datasets</a><ul>
<li class="toctree-l2"><a class="reference internal" href="package_reference/data.html#librimix">LibriMix</a></li>
<li class="toctree-l2"><a class="reference internal" href="package_reference/data.html#wsj0mix">Wsj0mix</a></li>
<li class="toctree-l2"><a class="reference internal" href="package_reference/data.html#wham">WHAM!</a></li>
<li class="toctree-l2"><a class="reference internal" href="package_reference/data.html#whamr">WHAMR!</a></li>
<li class="toctree-l2"><a class="reference internal" href="package_reference/data.html#sms-wsj">SMS-WSJ</a></li>
<li class="toctree-l2"><a class="reference internal" href="package_reference/data.html#kinectwsjmix">KinectWSJMix</a></li>
<li class="toctree-l2"><a class="reference internal" href="package_reference/data.html#dnsdataset">DNSDataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="package_reference/data.html#musdb18">MUSDB18</a></li>
<li class="toctree-l2"><a class="reference internal" href="package_reference/data.html#avspeech">AVSpeech</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="package_reference/filterbanks.html">Filterbank API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="package_reference/filterbanks.html#filterbank-encoder-and-decoder">Filterbank, Encoder and Decoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="package_reference/filterbanks.html#learnable-filterbanks">Learnable filterbanks</a><ul>
<li class="toctree-l3"><a class="reference internal" href="package_reference/filterbanks.html#module-asteroid.filterbanks.free_fb"><span class="hidden-section">Free</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="package_reference/filterbanks.html#analytic-free"><span class="hidden-section">Analytic Free</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="package_reference/filterbanks.html#parameterized-sinc"><span class="hidden-section">Parameterized Sinc</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="package_reference/filterbanks.html#fixed-filterbanks">Fixed filterbanks</a><ul>
<li class="toctree-l3"><a class="reference internal" href="package_reference/filterbanks.html#module-asteroid.filterbanks.stft_fb"><span class="hidden-section">STFT</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="package_reference/filterbanks.html#mp-gtfb"><span class="hidden-section">MP-GTFB</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="package_reference/filterbanks.html#transforms">Transforms</a><ul>
<li class="toctree-l3"><a class="reference internal" href="package_reference/filterbanks.html#griffin-lim-and-misi"><span class="hidden-section">Griffin-Lim and MISI</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="package_reference/filterbanks.html#module-asteroid.filterbanks.transforms"><span class="hidden-section">Complex transforms</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="package_reference/blocks.html">DNN building blocks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="package_reference/blocks.html#module-asteroid.masknn.convolutional">Convolutional blocks</a></li>
<li class="toctree-l2"><a class="reference internal" href="package_reference/blocks.html#module-asteroid.masknn.recurrent">Recurrent blocks</a></li>
<li class="toctree-l2"><a class="reference internal" href="package_reference/blocks.html#module-asteroid.masknn.norms">Norms</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="package_reference/models.html">Models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="package_reference/models.html#module-asteroid.models.base_models">Base classes</a></li>
<li class="toctree-l2"><a class="reference internal" href="package_reference/models.html#module-asteroid.models.conv_tasnet">Ready-to-use models</a></li>
<li class="toctree-l2"><a class="reference internal" href="package_reference/models.html#module-asteroid.models.zenodo">Publishing models</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="package_reference/losses.html">Losses &amp; Metrics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="package_reference/losses.html#module-asteroid.losses.pit_wrapper">Permutation invariant training (PIT) made easy</a></li>
<li class="toctree-l2"><a class="reference internal" href="package_reference/losses.html#available-loss-functions">Available loss functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="package_reference/losses.html#mse"><span class="hidden-section">MSE</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="package_reference/losses.html#sdr"><span class="hidden-section">SDR</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="package_reference/losses.html#pmsqe"><span class="hidden-section">PMSQE</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="package_reference/losses.html#stoi"><span class="hidden-section">STOI</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="package_reference/losses.html#multiscale-spectral-loss"><span class="hidden-section">MultiScale Spectral Loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="package_reference/losses.html#deep-clustering-affinity-loss"><span class="hidden-section">Deep clustering (Affinity) loss</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="package_reference/losses.html#computing-metrics">Computing metrics</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="package_reference/system.html">Lightning Wrapper</a></li>
<li class="toctree-l1"><a class="reference internal" href="package_reference/optimizers.html">Optimizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="package_reference/utils.html">Utils</a><ul>
<li class="toctree-l2"><a class="reference internal" href="package_reference/utils.html#parser-utils">Parser utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="package_reference/utils.html#module-asteroid.utils.torch_utils">Torch utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="package_reference/utils.html#module-asteroid.utils.hub_utils">Hub utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="package_reference/utils.html#module-asteroid.utils.generic_utils">Generic utils</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="package_reference/cli.html">CLI</a></li>
</ul>
<p class="caption"><span class="caption-text">Community</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="contribution_guide.html">Asteroid High-Level Contribution Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="contribution_guide.html#the-asteroid-contribution-process">The Asteroid Contribution Process</a></li>
<li class="toctree-l2"><a class="reference internal" href="contribution_guide.html#getting-started">Getting Started</a><ul>
<li class="toctree-l3"><a class="reference internal" href="contribution_guide.html#proposing-new-features">Proposing new features</a></li>
<li class="toctree-l3"><a class="reference internal" href="contribution_guide.html#reporting-issues">Reporting Issues</a></li>
<li class="toctree-l3"><a class="reference internal" href="contribution_guide.html#implementing-features-or-fixing-bugs">Implementing Features or Fixing Bugs</a></li>
<li class="toctree-l3"><a class="reference internal" href="contribution_guide.html#adding-tutorials">Adding Tutorials</a></li>
<li class="toctree-l3"><a class="reference internal" href="contribution_guide.html#improving-documentation-tutorials">Improving Documentation &amp; Tutorials</a></li>
<li class="toctree-l3"><a class="reference internal" href="contribution_guide.html#participating-in-online-discussions">Participating in online discussions</a></li>
<li class="toctree-l3"><a class="reference internal" href="contribution_guide.html#submitting-pull-requests-to-fix-open-issues">Submitting pull requests to fix open issues</a></li>
<li class="toctree-l3"><a class="reference internal" href="contribution_guide.html#reviewing-open-pull-requests">Reviewing open pull requests</a></li>
<li class="toctree-l3"><a class="reference internal" href="contribution_guide.html#improving-code-readability">Improving code readability</a></li>
<li class="toctree-l3"><a class="reference internal" href="contribution_guide.html#adding-test-cases-to-make-the-codebase-more-robust">Adding test cases to make the codebase more robust</a></li>
<li class="toctree-l3"><a class="reference internal" href="contribution_guide.html#promoting-asteroid">Promoting Asteroid</a></li>
<li class="toctree-l3"><a class="reference internal" href="contribution_guide.html#triaging-issues">Triaging issues</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="contribution_guide.html#about-open-source-development">About open source development</a></li>
<li class="toctree-l2"><a class="reference internal" href="contribution_guide.html#common-mistakes-to-avoid">Common Mistakes To Avoid</a></li>
<li class="toctree-l2"><a class="reference internal" href="contribution_guide.html#frequently-asked-questions">Frequently asked questions</a></li>
<li class="toctree-l2"><a class="reference internal" href="contribution_guide.html#attribution">Attribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="readmes/CONTRIBUTING.html">How to contribute</a><ul>
<li class="toctree-l2"><a class="reference internal" href="readmes/CONTRIBUTING.html#source-code-contributions">Source code contributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="readmes/CONTRIBUTING.html#writing-new-recipes">Writing new recipes.</a></li>
<li class="toctree-l2"><a class="reference internal" href="readmes/CONTRIBUTING.html#improving-the-docs">Improving the docs.</a></li>
<li class="toctree-l2"><a class="reference internal" href="readmes/CONTRIBUTING.html#coding-style">Coding style</a></li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">asteroid</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Datasets and tasks</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/supported_datasets.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="datasets-and-tasks">
<h1>Datasets and tasks<a class="headerlink" href="#datasets-and-tasks" title="Permalink to this headline">Â¶</a></h1>
<p>The following is a list of supported datasets, sorted by task.</p>
<div class="section" id="speech-separation">
<h2>Speech separation<a class="headerlink" href="#speech-separation" title="Permalink to this headline">Â¶</a></h2>
<div class="section" id="wsj0-2mix-dataset">
<h3>wsj0-2mix dataset<a class="headerlink" href="#wsj0-2mix-dataset" title="Permalink to this headline">Â¶</a></h3>
<p>wsj0-2mix is a single channel speech separation dataset base on WSJ0.
Three speaker extension (wsj0-3mix) is also considered here.</p>
<p><strong>Reference</strong></p>
<div class="highlight-BibTex notranslate"><div class="highlight"><pre><span></span><span class="nc">@article</span><span class="p">{</span><span class="nl">Hershey_2016</span><span class="p">,</span>
   <span class="na">title</span><span class="p">=</span><span class="s">{Deep clustering: Discriminative embeddings for segmentation and separation}</span><span class="p">,</span>
   <span class="na">ISBN</span><span class="p">=</span><span class="s">{9781479999880}</span><span class="p">,</span>
   <span class="na">url</span><span class="p">=</span><span class="s">{http://dx.doi.org/10.1109/ICASSP.2016.7471631}</span><span class="p">,</span>
   <span class="na">DOI</span><span class="p">=</span><span class="s">{10.1109/icassp.2016.7471631}</span><span class="p">,</span>
   <span class="na">journal</span><span class="p">=</span><span class="s">{2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}</span><span class="p">,</span>
   <span class="na">publisher</span><span class="p">=</span><span class="s">{IEEE}</span><span class="p">,</span>
   <span class="na">author</span><span class="p">=</span><span class="s">{Hershey, John R. and Chen, Zhuo and Le Roux, Jonathan and Watanabe, Shinji}</span><span class="p">,</span>
   <span class="na">year</span><span class="p">=</span><span class="s">{2016}</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="wham-dataset">
<h3>WHAM dataset<a class="headerlink" href="#wham-dataset" title="Permalink to this headline">Â¶</a></h3>
<p>WHAM! is a noisy single-channel speech separation dataset based on WSJ0.
It is a noisy extension of <a class="reference external" href="./../wsj0-mix/">wsj0-2mix</a>.</p>
<p>More info <a class="reference external" href="http://wham.whisper.ai/">here</a>.</p>
<p><strong>References</strong></p>
<div class="highlight-BibTex notranslate"><div class="highlight"><pre><span></span><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">WHAMWichern2019</span><span class="p">,</span>
  <span class="na">author</span><span class="p">=</span><span class="s">{Gordon Wichern and Joe Antognini and Michael Flynn and Licheng Richard Zhu and Emmett McQuinn and Dwight Crow and Ethan Manilow and Jonathan Le Roux}</span><span class="p">,</span>
  <span class="na">title</span><span class="p">=</span><span class="s">{{WHAM!: extending speech separation to noisy environments}}</span><span class="p">,</span>
  <span class="na">year</span><span class="p">=</span><span class="m">2019</span><span class="p">,</span>
  <span class="na">booktitle</span><span class="p">=</span><span class="s">{Proc. Interspeech}</span><span class="p">,</span>
  <span class="na">pages</span><span class="p">=</span><span class="s">{1368--1372}</span><span class="p">,</span>
  <span class="na">doi</span><span class="p">=</span><span class="s">{10.21437/Interspeech.2019-2821}</span><span class="p">,</span>
  <span class="na">url</span><span class="p">=</span><span class="s">{http://dx.doi.org/10.21437/Interspeech.2019-2821}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="whamr-dataset">
<h3>WHAMR dataset<a class="headerlink" href="#whamr-dataset" title="Permalink to this headline">Â¶</a></h3>
<p>WHAMR! is a noisy and reverberant single-channel speech separation dataset
based on WSJ0.
It is a reverberant extension of <a class="reference external" href="./../wham">WHAM!</a>.</p>
<p>Note that WHAMR! can synthesize binaural recordings, but we only consider
the single channel for now.</p>
<p>More info <a class="reference external" href="http://wham.whisper.ai/">here</a>.
<strong>References</strong></p>
<div class="highlight-BibTex notranslate"><div class="highlight"><pre><span></span><span class="nc">@misc</span><span class="p">{</span><span class="nl">maciejewski2019whamr</span><span class="p">,</span>
    <span class="na">title</span><span class="p">=</span><span class="s">{WHAMR!: Noisy and Reverberant Single-Channel Speech Separation}</span><span class="p">,</span>
    <span class="na">author</span><span class="p">=</span><span class="s">{Matthew Maciejewski and Gordon Wichern and Emmett McQuinn and Jonathan Le Roux}</span><span class="p">,</span>
    <span class="na">year</span><span class="p">=</span><span class="s">{2019}</span><span class="p">,</span>
    <span class="na">eprint</span><span class="p">=</span><span class="s">{1910.10279}</span><span class="p">,</span>
    <span class="na">archivePrefix</span><span class="p">=</span><span class="s">{arXiv}</span><span class="p">,</span>
    <span class="na">primaryClass</span><span class="p">=</span><span class="s">{cs.SD}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="librimix-dataset">
<h3>LibriMix dataset<a class="headerlink" href="#librimix-dataset" title="Permalink to this headline">Â¶</a></h3>
<p>The LibriMix dataset is an open source dataset
derived from LibriSpeech dataset. Itâ€™s meant as an alternative and complement
to <a class="reference external" href="./../wham/">WHAM</a>.</p>
<p>More info <a class="reference external" href="https://github.com/JorisCos/LibriMix">here</a>.</p>
<p><strong>References</strong></p>
<div class="highlight-BibTeX notranslate"><div class="highlight"><pre><span></span><span class="nc">@misc</span><span class="p">{</span><span class="nl">cosentino2020librimix</span><span class="p">,</span>
    <span class="na">title</span><span class="p">=</span><span class="s">{LibriMix: An Open-Source Dataset for Generalizable Speech Separation}</span><span class="p">,</span>
    <span class="na">author</span><span class="p">=</span><span class="s">{Joris Cosentino and Manuel Pariente and Samuele Cornell and Antoine Deleforge and Emmanuel Vincent}</span><span class="p">,</span>
    <span class="na">year</span><span class="p">=</span><span class="s">{2020}</span><span class="p">,</span>
    <span class="na">eprint</span><span class="p">=</span><span class="s">{2005.11262}</span><span class="p">,</span>
    <span class="na">archivePrefix</span><span class="p">=</span><span class="s">{arXiv}</span><span class="p">,</span>
    <span class="na">primaryClass</span><span class="p">=</span><span class="s">{eess.AS}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="kinect-wsj-dataset">
<h3>Kinect-WSJ dataset<a class="headerlink" href="#kinect-wsj-dataset" title="Permalink to this headline">Â¶</a></h3>
<p>Kinect-WSJ is a reverberated, noisy version of the WSJ0-2MIX dataset.
Microphones are placed on a linear array with spacing between the devices
resembling that of Microsoft Kinect â„¢, the device used to record the CHiME-5 dataset.
This was done so that we could use the real ambient noise captured as part of CHiME-5 dataset.
The room impulse responses (RIR) were simulated for a sampling rate of 16,000 Hz.</p>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>wsj_path :  Path to precomputed wsj-2mix dataset. Should contain the folder 2speakers/wav16k/.
If you donâ€™t have wsj_mix dataset, please create it using the scripts in egs/wsj0_mix</p></li>
<li><p>chime_path : Path to chime-5 dataset. Should contain the folders train, dev and eval</p></li>
<li><p>dihard_path : Path to dihard labels. Should contain <code class="docutils literal notranslate"><span class="pre">*.lab</span></code> files for the train and dev set</p></li>
</ul>
<p><strong>References</strong><span class="raw-html-m2r"><br></span>
<a class="reference external" href="https://github.com/sunits/Reverberated_WSJ_2MIX/">Original repo</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@inproceedings</span><span class="p">{</span><span class="n">sivasankaran2020</span><span class="p">,</span>
  <span class="n">booktitle</span> <span class="o">=</span> <span class="p">{</span><span class="mi">2020</span> <span class="mi">28</span><span class="n">th</span> <span class="p">{{</span><span class="n">European</span> <span class="n">Signal</span> <span class="n">Processing</span> <span class="n">Conference</span><span class="p">}}</span> <span class="p">({{</span><span class="n">EUSIPCO</span><span class="p">}})},</span>
  <span class="n">title</span><span class="o">=</span><span class="p">{</span><span class="n">Analyzing</span> <span class="n">the</span> <span class="n">impact</span> <span class="n">of</span> <span class="n">speaker</span> <span class="n">localization</span> <span class="n">errors</span> <span class="n">on</span> <span class="n">speech</span> <span class="n">separation</span> <span class="k">for</span> <span class="n">automatic</span> <span class="n">speech</span> <span class="n">recognition</span><span class="p">},</span>
  <span class="n">author</span><span class="o">=</span><span class="p">{</span><span class="n">Sunit</span> <span class="n">Sivasankaran</span> <span class="ow">and</span> <span class="n">Emmanuel</span> <span class="n">Vincent</span> <span class="ow">and</span> <span class="n">Dominique</span> <span class="n">Fohr</span><span class="p">},</span>
  <span class="n">year</span><span class="o">=</span><span class="p">{</span><span class="mi">2021</span><span class="p">},</span>
  <span class="n">month</span> <span class="o">=</span> <span class="n">Jan</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="sms-wsj-dataset">
<h3>SMS_WSJ dataset<a class="headerlink" href="#sms-wsj-dataset" title="Permalink to this headline">Â¶</a></h3>
<p>SMS_WSJ (stands for Spatialized Multi-Speaker Wall Street Journal)
is a multichannel source separation dataset, based on WSJ0 and WSJ1.</p>
<p>All the information regarding the dataset can be found in
<a class="reference external" href="https://github.com/fgnt/sms_wsj">this repo</a>.</p>
<p><strong>References</strong>
If you use this dataset, please cite the corresponding paper as follows :</p>
<div class="highlight-BibTex notranslate"><div class="highlight"><pre><span></span><span class="nc">@Article</span><span class="p">{</span><span class="nl">SmsWsj19</span><span class="p">,</span>
  <span class="na">author</span>    <span class="p">=</span> <span class="s">{Drude, Lukas and Heitkaemper, Jens and Boeddeker, Christoph and Haeb-Umbach, Reinhold}</span><span class="p">,</span>
  <span class="na">title</span>     <span class="p">=</span> <span class="s">{{SMS-WSJ}: Database, performance measures, and baseline recipe for multi-channel source separation and recognition}</span><span class="p">,</span>
  <span class="na">journal</span>   <span class="p">=</span> <span class="s">{arXiv preprint arXiv:1910.13934}</span><span class="p">,</span>
  <span class="na">year</span>      <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="speech-enhancement">
<h2>Speech enhancement<a class="headerlink" href="#speech-enhancement" title="Permalink to this headline">Â¶</a></h2>
<div class="section" id="dns-challenge-s-dataset">
<h3>DNS Challengeâ€™s dataset<a class="headerlink" href="#dns-challenge-s-dataset" title="Permalink to this headline">Â¶</a></h3>
<p>The Deep Noise Suppression (DNS) Challenge is a single-channel speech enhancement
challenge organized by Microsoft, with a focus on real-time applications.
More info can be found on the <a class="reference external" href="https://dns-challenge.azurewebsites.net/">official page</a>.</p>
<p><strong>References</strong></p>
<ul>
<li><p>The challenge paper, <a class="reference external" href="https://arxiv.org/abs/2001.08662">here</a>.
.. code-block:: BibTex</p>
<blockquote>
<div><p>&#64;misc{DNSChallenge2020,
title={The INTERSPEECH 2020 Deep Noise Suppression Challenge: Datasets, Subjective Speech Quality and Testing Framework},
author={Chandan K. A. Reddy and Ebrahim Beyrami and Harishchandra Dubey and Vishak Gopal and Roger Cheng and Ross Cutler and Sergiy Matusevych and Robert Aichner and Ashkan Aazami and Sebastian Braun and Puneet Rana and Sriram Srinivasan and Johannes Gehrke}, year={2020},
eprint={2001.08662},
}</p>
</div></blockquote>
</li>
<li><p>The baseline paper, <a class="reference external" href="https://arxiv.org/abs/2001.10601">here</a>.
.. code-block:: BibTex</p>
<blockquote>
<div><p>&#64;misc{xia2020weighted,
title={Weighted Speech Distortion Losses for Neural-network-based Real-time Speech Enhancement},
author={Yangyang Xia and Sebastian Braun and Chandan K. A. Reddy and Harishchandra Dubey and Ross Cutler and Ivan Tashev},
year={2020},
eprint={2001.10601},
}</p>
</div></blockquote>
</li>
</ul>
</div>
</div>
<div class="section" id="music-source-separation">
<h2>Music source separation<a class="headerlink" href="#music-source-separation" title="Permalink to this headline">Â¶</a></h2>
<div class="section" id="musdb18-dataset">
<h3>MUSDB18 Dataset<a class="headerlink" href="#musdb18-dataset" title="Permalink to this headline">Â¶</a></h3>
<p>The musdb18 is a dataset of 150 full lengths music tracks (~10h duration) of different genres along with their isolated drums, bass, vocals and others stems.</p>
<p>More info <a class="reference external" href="https://sigsep.github.io/datasets/musdb.html">here</a>.</p>
</div>
</div>
<div class="section" id="environmental-sound-separation">
<h2>Environmental sound separation<a class="headerlink" href="#environmental-sound-separation" title="Permalink to this headline">Â¶</a></h2>
<div class="section" id="fuss-dataset">
<h3>FUSS dataset<a class="headerlink" href="#fuss-dataset" title="Permalink to this headline">Â¶</a></h3>
<p>The Free Universal Sound Separation (FUSS) dataset comprises audio mixtures of arbitrary sounds with source references for use in experiments on arbitrary sound separation.</p>
<p>All the information related to this dataset can be found in <a class="reference external" href="https://github.com/google-research/sound-separation/tree/master/datasets/fuss">this repo</a>.</p>
<p><strong>References</strong>
If you use this dataset, please cite the corresponding paper as follows:</p>
<div class="highlight-BibTex notranslate"><div class="highlight"><pre><span></span><span class="nc">@Article</span><span class="p">{</span><span class="nl">Wisdom2020</span><span class="p">,</span>
  <span class="na">author</span>    <span class="p">=</span> <span class="s">{Scott Wisdom and Hakan Erdogan and Daniel P. W. Ellis and Romain Serizel and Nicolas Turpault and Eduardo Fonseca and Justin Salamon and Prem Seetharaman and John R. Hershey}</span><span class="p">,</span>
  <span class="na">title</span>     <span class="p">=</span> <span class="s">{What&#39;s All the FUSS About Free Universal Sound Separation Data?}</span><span class="p">,</span>
  <span class="na">journal</span>   <span class="p">=</span> <span class="s">{in preparation}</span><span class="p">,</span>
  <span class="na">year</span>      <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="audio-visual-source-separation">
<h2>Audio-visual source separation<a class="headerlink" href="#audio-visual-source-separation" title="Permalink to this headline">Â¶</a></h2>
<div class="section" id="avspeech-dataset">
<h3>AVSpeech dataset<a class="headerlink" href="#avspeech-dataset" title="Permalink to this headline">Â¶</a></h3>
<p>AVSpeech is an audio-visual speech separation dataset which was introduced by Google
in this article <a class="reference external" href="https://arxiv.org/abs/1804.03619">Looking to Listen at the Cocktail Party:
A Speaker-Independent Audio-Visual Model for Speech
Separation</a>.</p>
<p>More info <a class="reference external" href="https://looking-to-listen.github.io/avspeech/download.html">here</a>.</p>
<p><strong>References</strong></p>
<div class="highlight-BibTex notranslate"><div class="highlight"><pre><span></span><span class="nc">@article</span><span class="p">{</span><span class="nl">Ephrat_2018</span><span class="p">,</span>
   <span class="na">title</span><span class="p">=</span><span class="s">{Looking to listen at the cocktail party}</span><span class="p">,</span>
   <span class="na">volume</span><span class="p">=</span><span class="s">{37}</span><span class="p">,</span>
   <span class="na">url</span><span class="p">=</span><span class="s">{http://dx.doi.org/10.1145/3197517.3201357}</span><span class="p">,</span>
   <span class="na">DOI</span><span class="p">=</span><span class="s">{10.1145/3197517.3201357}</span><span class="p">,</span>
   <span class="na">journal</span><span class="p">=</span><span class="s">{ACM Transactions on Graphics}</span><span class="p">,</span>
   <span class="na">publisher</span><span class="p">=</span><span class="s">{Association for Computing Machinery (ACM)}</span><span class="p">,</span>
   <span class="na">author</span><span class="p">=</span><span class="s">{Ephrat, Ariel and Mosseri, Inbar and Lang, Oran and Dekel, Tali and Wilson, Kevin and Hassidim, Avinatan and Freeman, William T. and Rubinstein, Michael}</span><span class="p">,</span>
   <span class="na">year</span><span class="p">=</span><span class="s">{2018}</span><span class="p">,</span>
   <span class="na">pages</span><span class="p">=</span><span class="s">{1â€“11}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="speaker-extraction">
<h2>Speaker extraction<a class="headerlink" href="#speaker-extraction" title="Permalink to this headline">Â¶</a></h2>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="training_and_evaluation.html" class="btn btn-neutral float-right" title="Training and Evaluation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="readmes/egs_README.html" class="btn btn-neutral float-left" title="What is a recipe?" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Oncoming

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>